# We plot experimental results

import numpy as np
import matplotlib.pyplot as plt

# model compare
a = {}
# cnn
x = [0.8793218401695776, 0.9458996094866178, 0.957472140203829, 0.9627583579331741, 0.9665206210115249, 0.9685208115058577, 0.969854271835413, 0.9737594056576817, 0.9758548433127341, 0.9763787027335937, 0.9779026573959425, 0.9792837413030189, 0.9799504714734737, 0.9811886846366321, 0.9816649204686161, 0.9813315553805501, 0.9819506619678064, 0.9831412515477664, 0.9831888751309649, 0.9819982855510049, 0.9829983807981713, 0.9839032288789409, 0.9835222402133537, 0.9836174873797504, 0.9839032288789409, 0.9836651109572717, 0.9848557005372317, 0.9853795599580912, 0.9855700542908848, 0.9847604533765121]
y = [0.9472222222222222, 0.9442222222222222, 0.9581111111111111, 0.9363333333333334, 0.9707777777777777, 0.9696666666666667, 0.9793333333333333, 0.9767777777777777, 0.9756666666666667, 0.9833333333333333, 0.977, 0.9707777777777777, 0.9804444444444445, 0.9784444444444444, 0.9792222222222222, 0.9518888888888889, 0.9763333333333334, 0.9824444444444445, 0.9824444444444445, 0.9823333333333333, 0.9778888888888889, 0.9801111111111112, 0.9782222222222222, 0.982, 0.9798888888888889, 0.9518888888888889, 0.9746666666666667, 0.9862222222222222, 0.9815555555555555, 0.9766666666666667]
#y = y[:20]
a["cnn (we used)"] = y

# cnn2
#[0.8056005333784546, 0.9151823983179727, 0.9336127250214307, 0.940803886084389, 0.9421849699971426, 0.9464710924849986, 0.9471378226497762, 0.948661777312125, 0.9477569292313553, 0.9514239451376322, 0.9517096866368225, 0.9523287932184018, 0.9543289837127346, 0.9534241356262878, 0.9553767025374221, 0.9553290789599009, 0.9564720449566625, 0.957138775115763, 0.9566149157005805, 0.9597104486084765]
y2 = [0.8791111111111111, 0.9347777777777778, 0.9257777777777778, 0.9341111111111111, 0.9456666666666667, 0.9502222222222222, 0.9526666666666667, 0.9557777777777777, 0.9402222222222222, 0.9496666666666667, 0.9385555555555556, 0.9561111111111111, 0.9347777777777778, 0.9551111111111111, 0.951, 0.9504444444444444, 0.9173333333333333, 0.9498888888888889, 0.9424444444444444, 0.9591111111111111]
a["cnn2"] = y2

# cnn3
#[0.875178588436994, 0.9481855414744638, 0.9564244213677869, 0.9653776550090861, 0.9693780360034289, 0.9721878274121345, 0.9724259453281265, 0.9749976188208401, 0.9747118773216497, 0.9758548433184113, 0.9771406800647681, 0.9765691970663872, 0.9785693875607201, 0.978807505476712, 0.9770454328983713, 0.9781407753119344, 0.9775692923135537, 0.977616915896752, 0.9802362129783412, 0.9771883036479665]
y3 = [0.8916666666666667, 0.8834444444444445, 0.6808888888888889, 0.9651111111111111, 0.9668888888888889, 0.9732222222222222, 0.9678888888888889, 0.9768888888888889, 0.9415555555555556, 0.9681111111111111, 0.9727777777777777, 0.9804444444444445, 0.9681111111111111, 0.9838888888888889, 0.979, 0.9821111111111112, 0.9822222222222222, 0.9717777777777777, 0.945, 0.9745555555555555]
a["cnn3"] = y3

# cnn4
#[0.8765596723497476, 0.9482331650690166, 0.9572340222878369, 0.9643299361843986, 0.9689494237546433, 0.9702352605010001, 0.9719973330793409, 0.9737594056576817, 0.9732355462424993, 0.9745690065720545, 0.9753309839032289, 0.9762358319839984, 0.9743785122392609, 0.9745213829831789, 0.9765691970607101, 0.9746642537384513, 0.9753786074864272, 0.9731402990761024, 0.9732831698200205, 0.9731402990704253]
y4 = [0.9134444444444444, 0.9492222222222222, 0.9427777777777778, 0.9721111111111111, 0.9725555555555555, 0.9613333333333334, 0.9628888888888889, 0.975, 0.9623333333333334, 0.9794444444444445, 0.9703333333333334, 0.9771111111111112, 0.9641111111111111, 0.9587777777777777, 0.9475555555555556, 0.9795555555555555, 0.9734444444444444, 0.9738888888888889, 0.9594444444444444, 0.8655555555555555]
a["cnn4"] = y4

fig = plt.figure()
ax = fig.add_subplot(111)
ax.set_xlabel("epoch (times of using a set of training dataset)", size=14)
ax.set_ylabel("classification accuracy of test dataset (%)", size=14)

for i, v in a.items():
	ax.plot(list(range(1, len(v)+1)), v, linestyle="solid", marker='o', label=i)
ax.legend()
for i, j in zip(list(range(1, len(y)+1)), y):
	ax.annotate("{:.2f}".format(j), xy=(i, j), size=8)


# model fitting check
# cnn
x = [0.8728926564434708, 0.9428040765787218, 0.9493761310544238, 0.9556148204590913, 0.9605200495285265, 0.9634250881036289, 0.9663777502619297, 0.9693780360034289, 0.9691399180874369, 0.9710924849985713, 0.9730926754929041, 0.9726640632441185, 0.9735212877416897, 0.9743308886560624, 0.9737594056576817, 0.9759024669016096, 0.9762834555671969, 0.9758548433184113, 0.9749499952376417, 0.9775216687303553, 0.9780931517287361, 0.976426326316792, 0.9752357367368321, 0.9759500904848081, 0.9774740451414797, 0.9772359272311649, 0.9753786074864272, 0.9754262310696257, 0.9745690065720545, 0.9773311743975617, 0.9749976188208401, 0.9757595961520145, 0.9750928659872369, 0.9741403943175917, 0.9752833603200305, 0.9766168206495857, 0.9741880179064673, 0.9748547480712448, 0.9738546528240785, 0.9758548433184113, 0.9754738546528241, 0.9742832650728641, 0.9753309839032289, 0.9753309839032289, 0.9734736641584912, 0.9741880179064673, 0.9740927707457476, 0.9741403943175917, 0.975711972568816, 0.9739022764072769, 0.9726640632441185, 0.9731402990817797, 0.9739975235736736, 0.9733307934088961, 0.9743785122392609, 0.9735212877416897, 0.9717115915801505, 0.9719020859129441, 0.9716639679969521, 0.9741403943232689, 0.9721402038289361, 0.9697590246690161, 0.9704733784169921, 0.9734736641528141, 0.9722354509953329, 0.9719020859129441, 0.9736641584912848, 0.9721402038289361, 0.9728069339937137, 0.9732831698256977, 0.9721402038289361, 0.9717115915801505, 0.9721878274121345, 0.9715687208305553, 0.9696637775026193, 0.9721402038289361, 0.9717115915801505, 0.9714734736641585, 0.9724735689056477, 0.9728069339937137, 0.9692351652481566, 0.9712829793313649, 0.9729974283265073, 0.9712829793256877, 0.9719497094961425, 0.9679969520906753, 0.9701400133346033, 0.9714258500752829, 0.9701400133346033, 0.9721402038289361, 0.9678540813410801, 0.9715210972473569, 0.9696637775026193, 0.9708543670825793, 0.9712353557481664, 0.9671397275931041, 0.9676635870082865, 0.969854271835413, 0.9663777502619297, 0.9659967615963425]
y = [0.9226666666666666, 0.9631111111111111, 0.8528888888888889, 0.9727777777777777, 0.9592222222222222, 0.9767777777777777, 0.9796666666666667, 0.9775555555555555, 0.9797777777777777, 0.9742222222222222, 0.9732222222222222, 0.935, 0.9684444444444444, 0.973, 0.9792222222222222, 0.9762222222222222, 0.98, 0.9827777777777778, 0.9675555555555555, 0.9798888888888889, 0.9777777777777777, 0.9691111111111111, 0.9806666666666667, 0.9518888888888889, 0.9342222222222222, 0.969, 0.9757777777777777, 0.9748888888888889, 0.9813333333333333, 0.9702222222222222, 0.9805555555555555, 0.9761111111111112, 0.9767777777777777, 0.9144444444444444, 0.9723333333333334, 0.9745555555555555, 0.9773333333333334, 0.9746666666666667, 0.9584444444444444, 0.9765555555555555, 0.9776666666666667, 0.979, 0.9555555555555556, 0.9552222222222222, 0.975, 0.9758888888888889, 0.8591111111111112, 0.9693333333333334, 0.9666666666666667, 0.9523333333333334, 0.9754444444444444, 0.9752222222222222, 0.963, 0.9473333333333334, 0.9553333333333334, 0.9576666666666667, 0.9748888888888889, 0.9735555555555555, 0.9598888888888889, 0.9671111111111111, 0.9692222222222222, 0.9706666666666667, 0.9778888888888889, 0.945, 0.9427777777777778, 0.9796666666666667, 0.95, 0.9618888888888889, 0.9761111111111112, 0.9755555555555555, 0.9423333333333334, 0.9734444444444444, 0.9725555555555555, 0.9705555555555555, 0.9767777777777777, 0.9706666666666667, 0.9753333333333334, 0.9672222222222222, 0.9548888888888889, 0.9774444444444444, 0.9346666666666666, 0.9745555555555555, 0.9727777777777777, 0.971, 0.9741111111111111, 0.9786666666666667, 0.9738888888888889, 0.945, 0.9767777777777777, 0.981, 0.9697777777777777, 0.9726666666666667, 0.9642222222222222, 0.9642222222222222, 0.9427777777777778, 0.9608888888888889, 0.9464444444444444, 0.9428888888888889, 0.9633333333333334, 0.9584444444444444]
fig = plt.figure()
ax = fig.add_subplot(111)
ax.set_xlabel("epoch (times of using a set of training dataset)", size=14)
ax.set_ylabel("classification accuracy (%)", size=14)
for i, v in {"training dataset": x, "test dataset": y}.items():
	ax.plot(list(range(1, len(v)+1)), v, linestyle="solid", marker='o', label=i)
	for i, j in zip(list(range(1, len(y)+1)), y):
		if i % 3 == 0:
			ax.annotate("{:.2f}".format(j), xy=(i, j), size=8)
ax.legend()